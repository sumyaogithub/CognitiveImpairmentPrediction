{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  # 显示所有列\n",
    "pd.set_option('display.max_rows', None)  # 显示所有行\n",
    "import numpy as np\n",
    "#import jieba\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold,train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "import math\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pandas import Series\n",
    "from sklearn import metrics\n",
    "import pandas\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "from random import randint\n",
    "from sqlite3 import adapters\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import learning_curve, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.impute import SimpleImputer  #导包\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector:\n",
    "    def __init__(self, X, y, featurenum_criteria):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.featurenum_criteria = featurenum_criteria\n",
    "\n",
    "    def pearson_corr(self):\n",
    "        corr_scores = []\n",
    "        for col in self.X.columns:\n",
    "            corr_score, _ = pearsonr(self.X[col], self.y)\n",
    "            corr_scores.append((col, abs(corr_score)))\n",
    "        corr_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [col for col, _ in corr_scores[:self.featurenum_criteria]]\n",
    "\n",
    "    def chi_square(self):\n",
    "        selector = SelectKBest(chi2, k=self.featurenum_criteria)\n",
    "        selector.fit(self.X, self.y)\n",
    "        return self.X.columns[selector.get_support(indices=True)].tolist()\n",
    "\n",
    "    def RRE(self):\n",
    "        model = GradientBoostingClassifier()  # You can use any model of your choice\n",
    "        rfe = RFE(estimator=model, n_features_to_select=self.featurenum_criteria)\n",
    "        rfe.fit(self.X, self.y)\n",
    "        return self.X.columns[rfe.support_].tolist()\n",
    "\n",
    "    def embedded_lgbm(self):\n",
    "        model = GradientBoostingClassifier()\n",
    "        model.fit(self.X, self.y)\n",
    "        feature_importances = model.feature_importances_\n",
    "        feature_importances = pd.Series(feature_importances, index=self.X.columns)\n",
    "        feature_importances = feature_importances.sort_values(ascending=False)\n",
    "        return feature_importances.index[:self.featurenum_criteria].tolist()\n",
    "\n",
    "    def calculate_embedET(self, randomstate):\n",
    "        model = ExtraTreesClassifier(n_estimators=5, criterion='gini', max_features=2, random_state=randomstate)\n",
    "        model.fit(self.X, self.y)\n",
    "\n",
    "        features = pd.DataFrame()\n",
    "        features['names'] = self.X.columns\n",
    "        features['coef'] = abs(model.feature_importances_)\n",
    "        features = features.sort_values(by='coef', ascending=False)\n",
    "        num = self.featurenum_criteria if self.featurenum_criteria > 1 else math.ceil(\n",
    "            self.featurenum_criteria * (self.X.shape[0]))\n",
    "        data_sorted = features.head(num)\n",
    "        colnames_sorted = data_sorted['names'].values\n",
    "        return colnames_sorted[:self.featurenum_criteria]  # Ensure the same number of features\n",
    "\n",
    "    def calculate_embedRF(self, randomstate):\n",
    "        rf = RandomForestClassifier(n_estimators=30, max_depth=3, random_state=randomstate)\n",
    "        model = rf.fit(self.X, self.y)\n",
    "        features = pd.DataFrame()\n",
    "        features['names'] = self.X.columns\n",
    "        features['coef'] = abs(model.feature_importances_)\n",
    "        features = features.sort_values(by='coef', ascending=False)\n",
    "        num = self.featurenum_criteria if self.featurenum_criteria > 1 else math.ceil(\n",
    "            self.featurenum_criteria * (self.X.shape[0]))\n",
    "        data_sorted = features.head(num)\n",
    "        colnames_sorted = data_sorted['names'].values\n",
    "        return colnames_sorted[:self.featurenum_criteria]  # Ensure the same number of features\n",
    "\n",
    "    def integrated_feature_selection(self, random_state=None):\n",
    "        if random_state:\n",
    "            np.random.seed(random_state)\n",
    "\n",
    "        pearson_selected = self.pearson_corr()\n",
    "        chi_selected = self.chi_square()\n",
    "        rre_selected = self.RRE()\n",
    "        embedded_lgbm_selected = self.embedded_lgbm()\n",
    "        embedET_selected = self.calculate_embedET(random_state)\n",
    "        embedRF_selected = self.calculate_embedRF(random_state)\n",
    "\n",
    "        # Ensure the same number of features for all methods\n",
    "        all_selected = [\n",
    "            pearson_selected[:self.featurenum_criteria],\n",
    "            chi_selected[:self.featurenum_criteria],\n",
    "            rre_selected[:self.featurenum_criteria],\n",
    "            embedded_lgbm_selected[:self.featurenum_criteria],\n",
    "            embedET_selected[:self.featurenum_criteria],\n",
    "            embedRF_selected[:self.featurenum_criteria]\n",
    "        ]\n",
    "\n",
    "        # Voting mechanism\n",
    "        feature_votes = {}\n",
    "        for feature_list in all_selected:\n",
    "            for feature in feature_list:\n",
    "                if feature in feature_votes:\n",
    "                    feature_votes[feature] += 1\n",
    "                else:\n",
    "                    feature_votes[feature] = 1\n",
    "        sorted_votes = sorted(feature_votes.items(), key=lambda x: x[1], reverse=True)\n",
    "        final_selected_features = [feature for feature, _ in sorted_votes[:self.featurenum_criteria]]\n",
    "\n",
    "        return final_selected_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Pseudo-lable with putback(SS-PP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PseudoTotal():\n",
    "    def __init__(self,max_iter,basic_model,n_top,n_bottom,featnum_criteria,feature_traNum,put_back,model_use_Augment,need_model,fp):\n",
    "        self.max_iter=max_iter\n",
    "        self.n_top=n_top\n",
    "        self.n_bottom=n_bottom\n",
    "        self.basic_model=basic_model    \n",
    "        self.feature_traNum=feature_traNum\n",
    "        self.featnum_criteria=featnum_criteria\n",
    "        self.vote_criteria=2\n",
    "        #self.fp=fp\n",
    "        self.put_back=put_back\n",
    "        self.model_use_Augment=model_use_Augment\n",
    "        self.need_model=need_model\n",
    "        self.fp=fp\n",
    "\n",
    "    #step2 特征选择\n",
    "    def feature_selection_func(self,X,y,vote_criteria):\n",
    "        #print(y.tail(2))\n",
    "        feature=feature_selection(X=X,y=y,featurenum_criteria=self.featnum_criteria,vote_criteria=vote_criteria).main()\n",
    "        return feature\n",
    "    \n",
    "    def model_train(self,AugmentedX=None,AugmentedY =None,features=None,model=None,X_train=None,y_train=None):\n",
    "        #model=self.basic_model\n",
    "        if self.model_use_Augment==True: \n",
    "            cur_model=model.fit(AugmentedX[features],AugmentedY) \n",
    "        else: \n",
    "            cur_model=model.fit(X_train[features],y_train) \n",
    "        return(cur_model)   \n",
    "    \n",
    "    def model_assess(self,model,features,X_test,y_test):\n",
    "        '''specificity:特异性'''\n",
    "        pred_test = model.predict(X_test[features])\n",
    "        proba_test = model.predict_proba(X_test[features])[:, 1]\n",
    "        a = metrics.confusion_matrix(y_test, pred_test)\n",
    "        accuracy=metrics.accuracy_score(y_test, pred_test)\n",
    "        precision=metrics.precision_score(y_test, pred_test) \n",
    "        #AUC=metrics.roc_auc_score(y_test, proba_test)\n",
    "        recall=metrics.recall_score(y_test, pred_test)\n",
    "        F1 = metrics.f1_score(y_test, pred_test)\n",
    "        specificity=a[0][0]/(a[0][0]+a[0][1])\n",
    "        #specificity2=a[1][1]/(a[1][1]+a[1][0])这个就是召回率\n",
    "        Kappa=metrics.cohen_kappa_score(y_test, pred_test)\n",
    "        \n",
    "        #assDaFrame=pd.DataFrame([[accuracy,precision,recall,specificity,AUC,F1,Kappa]]) #注意]有两个\n",
    "        assDaFrame=pd.DataFrame([[accuracy,precision,recall,specificity,F1,Kappa]]) #注意]有两个\n",
    "        return assDaFrame,proba_test\n",
    "    \n",
    "    def AugmentData(self,features,cur_model,X_unlabled,X_train,y_train,):\n",
    "        unlable_copy_first=X_unlabled.copy(deep=True)\n",
    "        unlable_copy=unlable_copy_first[features].reset_index(drop=True) \n",
    "        \n",
    "        #print('---------unlable_copy------')\n",
    "        #print(unlable_copy.tail(2))\n",
    "        unlable_copy['unlable_copy_pre']=cur_model.predict(unlable_copy)\n",
    "        unlable_copy['unlable_copy_preprob']=cur_model.predict_proba(unlable_copy.iloc[:,:unlable_copy.shape[1]-1])[:,1]\n",
    "        unlable_copy['Pseudo_lable']=-1\n",
    "        \n",
    "        numtop=self.n_top if self.n_top>1 else self.n_top*(unlable_copy.shape[0])\n",
    "        numdown=self.n_bottom if self.n_bottom>1 else self.n_bottom*(unlable_copy.shape[0])\n",
    "\n",
    "        Pseudo_top=unlable_copy.sort_values(by='unlable_copy_preprob').head(numtop)\n",
    "        Pseudo_bottom=unlable_copy.sort_values(by='unlable_copy_preprob',ascending=False).head(numdown)\n",
    "        Pseudo_top['Pseudo_lable']=0\n",
    "        Pseudo_bottom['Pseudo_lable']=1\n",
    "        Pseudo=Pseudo_top.append(Pseudo_bottom)\n",
    "        Pseudo_index=[x for x in Pseudo.index]\n",
    "        #print(Pseudo_index)\n",
    "        \n",
    "        new_data=X_unlabled.iloc[Pseudo_index]\n",
    "        Augmented_X= X_train.append(new_data)\n",
    "        Augmented_Y = y_train.append(Pseudo['Pseudo_lable'])\n",
    "        \n",
    "        if self.put_back==True:\n",
    "            return Augmented_X,Augmented_Y\n",
    "        else:\n",
    "            unlablecopy_sort=unlable_copy.sort_values(by='unlable_copy_preprob')\n",
    "            median_last_line=unlablecopy_sort.shape[0]-numdown-1\n",
    "            Pseudo_median=unlablecopy_sort.iloc[numtop:median_last_line,:]  \n",
    "            Pseudo_median_index=list(Pseudo_median.index)\n",
    "            X_unlabled_append= X_unlabled.append(new_data)\n",
    "            X_unlabled=X_unlabled_append.drop_duplicates(subset=X_unlabled.columns, keep=False) #删除所有重复项，不保留\n",
    "            X_unlabled = X_unlabled.reset_index(drop=True)  #否则报错索引超出列表\n",
    "            #print(X_unlabled.shape[0])\n",
    "            return Augmented_X,Augmented_Y,X_unlabled\n",
    "   \n",
    "   \n",
    "    def main(self):\n",
    "        data=pd.read_csv(self.fp,encoding='gbk')\n",
    "        data.dropna(subset=data.columns.difference(['MMSESCORE']), inplace=True)\n",
    "        labeled_data = data[data['MMSESCORE'].notnull()]  \n",
    "        unlabeled_data = data[data['MMSESCORE'].isnull()] \n",
    "        X_unlabled=unlabeled_data\n",
    "\n",
    "        print(labeled_data.shape,unlabeled_data.shape)\n",
    "        print(\"标签均衡情况：\",labeled_data['MMSESCORE'].value_counts())\n",
    "        # 分离特征和目标列\n",
    "        X= labeled_data.drop(columns=['MMSESCORE',\"ID\"])\n",
    "        y = labeled_data['MMSESCORE']\n",
    "        \n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        total_assess = pd.DataFrame()\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            feature=FeatureSelector(X_train,y_train,self.feature_traNum).integrated_feature_selection(random_state=42)\n",
    "            \n",
    "            # supervised\n",
    "            assess_total=pd.DataFrame()\n",
    "            cur_model=self.model_train(AugmentedX=X_train,AugmentedY =y_train,features=feature,model=self.basic_model,X_train=X_train,y_train=y_train)\n",
    "            assess_score,proba_test=self.model_assess(model=cur_model,features=feature,X_test=X_test,y_test=y_test)\n",
    "            assess_total=assess_total.append(assess_score)\n",
    "\n",
    "            if self.put_back==True:\n",
    "                Augmented_X,Augmented_Y =self.AugmentData(features=feature,cur_model=cur_model,X_unlabled=X_unlabled,X_train=X_train,y_train=y_train)\n",
    "            else:\n",
    "                Augmented_X,Augmented_Y,X_unlabled =self.AugmentData(features=feature,cur_model=cur_model,X_unlabled=X_unlabled,X_train=X_train,y_train=y_train)\n",
    "            \n",
    "            # semi_pseudo\n",
    "\n",
    "\n",
    "            iter=1 \n",
    "            featureiter=1\n",
    "            while iter<=self.max_iter:\n",
    "                cur_model=self.model_train(AugmentedX=Augmented_X,AugmentedY =Augmented_Y,features=feature,model=cur_model,X_train=X_train,y_train=y_train)\n",
    "                assess_score,proba_test=self.model_assess(model=cur_model,features=feature,X_test=X_test,y_test=y_test)\n",
    "                if self.put_back==True:\n",
    "                    Augmented_X,Augmented_Y =self.AugmentData(features=feature,cur_model=cur_model,X_unlabled=X_unlabled,X_train=X_train,y_train=y_train)\n",
    "                else:\n",
    "                    Augmented_X,Augmented_Y,X_unlabled =self.AugmentData(features=feature,cur_model=cur_model,X_unlabled=X_unlabled,X_train=X_train,y_train=y_train)\n",
    "                \n",
    "                assess_total=assess_total.append(assess_score)\n",
    "                \n",
    "                iter+=1\n",
    "                featureiter+=1\n",
    "            \n",
    "            #columns=['accuracy','precision','recall','specificity','AUC','F1','Kappa']\n",
    "            columns=['accuracy','precision','recall','specificity','F1','Kappa']\n",
    "            assess_total.columns=columns\n",
    "            print(assess_total)\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            if self.need_model==True:\n",
    "                assess=[assess_total,y_test,proba_test]\n",
    "                data=[X_train, X_test, y_train, y_test]\n",
    "                dataAug=[Augmented_X,Augmented_Y]\n",
    "                model=[feature,cur_model]\n",
    "                #return assess_total,y_test,proba_test,feature,cur_model,X_train\n",
    "                return assess,data,dataAug,model,feature\n",
    "            else:\n",
    "                print(assess_total)\n",
    "                return assess_total\"\"\"\n",
    "            total_assess=total_assess.append(assess_total)\n",
    "    \n",
    "        print('训练轮次+交叉验证：',total_assess)\n",
    "        average_assess = total_assess.mean()\n",
    "        print('五折平均', average_assess)\n",
    "        return average_assess\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "a=PseudoTotal(max_iter=30,\n",
    "            basic_model=model,\n",
    "            n_top=10,n_bottom=10,\n",
    "            featnum_criteria=35,\n",
    "            feature_traNum=1,\n",
    "            put_back=True,\n",
    "            model_use_Augment=True,\n",
    "            need_model=False,\n",
    "            fp=\"9.dataset26criteria.csv\").main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1).base learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_num=32\n",
    "#基分类器  individual learner\n",
    "classifier_bys = MultinomialNB()\n",
    "classifier_svm = svm.SVC(random_state=random_num,max_iter=100000,probability=True)\n",
    "classifier_mlp = MLPClassifier(random_state=random_num)\n",
    "classifier_knn = KNeighborsClassifier(n_neighbors=10)\n",
    "classifier_lrclf = LogisticRegression()\n",
    "\n",
    "#集成学习\n",
    "#boosting\n",
    "classifier_ada = AdaBoostClassifier(random_state=random_num)\n",
    "classifier_gbc = GradientBoostingClassifier(random_state=random_num)\n",
    "classifier_xgb =XGBClassifier(random_state=random_num,eval_metric='mlogloss')\n",
    "classifier_lgbm = lgb.LGBMClassifier(random_state=random_num)\n",
    "#bagging\n",
    "classifier_rf = RandomForestClassifier(random_state=random_num)\n",
    "#stacking\n",
    "classifier_scclf_individual= StackingCVClassifier(classifiers=[classifier_bys,classifier_svm,classifier_mlp ,classifier_knn ,classifier_lrclf], meta_classifier=classifier_lrclf,cv=5,random_state=random_num)\n",
    "classifier_scclf_ensemble= StackingCVClassifier(classifiers=[classifier_ada,classifier_gbc,classifier_xgb ,classifier_lgbm,classifier_rf], meta_classifier=classifier_lrclf,cv=5,random_state=random_num)\n",
    "#voting\n",
    "voting_soft_individual= VotingClassifier(estimators=[\n",
    "    ('classifier_bys', classifier_bys),\n",
    "    ('classifier_svm', classifier_svm),\n",
    "    ('classifier_mlp ', classifier_mlp ),\n",
    "    ('classifier_lrclf',classifier_lrclf),\n",
    "    ('classifier_knn' ,classifier_knn )\n",
    "], voting='soft')\n",
    "voting_soft_ensemble= VotingClassifier(estimators=[\n",
    "    ('classifier_ada', classifier_ada),\n",
    "    ('classifier_gbc', classifier_gbc),\n",
    "    ('classifier_xgb ',classifier_xgb ),\n",
    "    ('classifier_lgbm',classifier_lgbm),\n",
    "    ('classifier_rf' ,classifier_rf )\n",
    "], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ensemble=[classifier_ada,classifier_gbc,classifier_xgb,classifier_lgbm,classifier_rf,classifier_scclf_ensemble,voting_soft_ensemble]\n",
    "model_ensemble0=[classifier_ada,classifier_gbc,classifier_xgb,classifier_lgbm,classifier_rf]\n",
    "model_ensemble1=[classifier_scclf_ensemble,voting_soft_ensemble]\n",
    "model_ensemble2=[classifier_scclf_individual,voting_soft_individual]\n",
    "model_individual=[classifier_bys,classifier_svm ,classifier_mlp,classifier_knn,classifier_lrclf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tranin_with_feature(basic_model):\n",
    "    asstotal=pd.DataFrame()\n",
    "    for featurenum in range(20,101,5):\n",
    "        #print(featurenum)            \n",
    "        average_assess=PseudoTotal(max_iter=30,\n",
    "            basic_model=model,\n",
    "            n_top=10,\n",
    "            n_bottom=10,\n",
    "            featnum_criteria=featurenum,\n",
    "            feature_traNum=1,\n",
    "            put_back=True,\n",
    "            model_use_Augment=True,\n",
    "            need_model=False,\n",
    "            fp=\"9.dataset26criteria.csv\").main()\n",
    "        assess['featurenum']=featurenum\n",
    "        asstotal=asstotal.append(average_assess)\n",
    "    return asstotal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) supervised machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_ensemble:\n",
    "    average_assess=PseudoTotal(max_iter=0,\n",
    "            basic_model=model,\n",
    "            n_top=10,\n",
    "            n_bottom=10,\n",
    "            featnum_criteria=featurenum,\n",
    "            feature_traNum=1,\n",
    "            put_back=True,\n",
    "            model_use_Augment=True,\n",
    "            need_model=False,\n",
    "            fp=\"9.dataset26criteria.csv\").main()\n",
    "for model in model_individual:\n",
    "    average_assess=PseudoTotal(max_iter=0,\n",
    "            basic_model=model,\n",
    "            n_top=10,\n",
    "            n_bottom=10,\n",
    "            featnum_criteria=featurenum,\n",
    "            feature_traNum=1,\n",
    "            put_back=True,\n",
    "            model_use_Augment=True,\n",
    "            need_model=False,\n",
    "            fp=\"9.dataset26criteria.csv\").main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) SS-PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeaturePath=os.getcwd()+'\\\\Data\\\\feature'\n",
    "for model in model_ensemble:\n",
    "    assess=tranin_with_feature(model)\n",
    "    patternloc=str(model).index('(')\n",
    "    model_name=str(model)[0:patternloc].replace('Classifier',\"\").replace('CV',\"\")\n",
    "    assess['model_name']=str(model_name)\n",
    "    assess.to_csv(FeaturePath+f'\\\\featureselection_{model_name}.csv',index=False)\n",
    "for model in model_ensemble2:\n",
    "    assess=tranin_with_feature(model)\n",
    "    patternloc=str(model).index('(')\n",
    "    model_name=str(model)[0:patternloc].replace('Classifier',\"\").replace('CV',\"\")\n",
    "    assess['model_name']='individual'+str(model_name)\n",
    "    assess.to_csv(FeaturePath+f'\\\\featureselection_individual_{model_name}.csv',index=False)\n",
    "for model in model_individual:\n",
    "    assess=tranin_with_feature(model)\n",
    "    patternloc=str(model).index('(')\n",
    "    model_name=str(model)[0:patternloc].replace('Classifier',\"\").replace('CV',\"\")\n",
    "    assess['model_name']=str(model_name)\n",
    "    assess.to_csv(FeaturePath+f'\\\\featureselection_{model_name}.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.SELF-TRAINING without putback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assess=PseudoTotal(max_iter=30,\n",
    "            basic_model=classifier_gbc ,\n",
    "            n_top=10,n_bottom=10,\n",
    "            featnum_criteria=35,\n",
    "            feature_traNum=1,\n",
    "            put_back=False,\n",
    "            model_use_Augment=True,\n",
    "            need_model=False,\n",
    "            fp=\"9.dataset26criteria.csv\").main()\n",
    "assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.CO-TRANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# 读取数据集\n",
    "#data = pd.read_csv(\"7.ADMMSE.csv\", encoding='gbk')\n",
    "data = pd.read_csv(\"9.dataset26criteria.csv\", encoding='gbk')\n",
    "data.dropna(subset=data.columns.difference(['MMSESCORE']), inplace=True)\n",
    "labeled_data = data[data['MMSESCORE'].notnull()]  \n",
    "unlabeled_data = data[data['MMSESCORE'].isnull()] \n",
    "\n",
    "X_unlabeled = unlabeled_data.drop(columns=['MMSESCORE', 'ID'])\n",
    "X_labeled = labeled_data.drop(columns=['MMSESCORE', 'ID'])\n",
    "y_labeled = labeled_data['MMSESCORE']\n",
    "\n",
    "def evaluate(y_true, y_pred, threshold=0.5):\n",
    "    # 将连续目标值转换为二元值\n",
    "    y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "    \n",
    "    # 计算评价指标\n",
    "    accuracy = accuracy_score(y_true, y_pred_binary)\n",
    "    precision = precision_score(y_true, y_pred_binary)\n",
    "    recall = recall_score(y_true, y_pred_binary)\n",
    "    f1 = f1_score(y_true, y_pred_binary)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    avg_precision = average_precision_score(y_true, y_pred)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, roc_auc, avg_precision\n",
    "\n",
    "# 定义随机森林分类器\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# 定义交叉验证\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 初始化两个分类器\n",
    "classifier1 = RandomForestClassifier(random_state=42)\n",
    "classifier2 = classifier_gbc\n",
    "\n",
    "# 定义迭代次数和停止条件\n",
    "max_iterations = 5\n",
    "iteration = 0\n",
    "stop_condition = False\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(X_labeled):\n",
    "    X_train, X_test = X_labeled.iloc[train_index], X_labeled.iloc[test_index]\n",
    "    y_train, y_test = y_labeled.iloc[train_index], y_labeled.iloc[test_index]\n",
    "\n",
    "    feature1=FeatureSelector(X_train,y_train,35).integrated_feature_selection(random_state=42)\n",
    "    feature2=FeatureSelector(X_train,y_train,40).integrated_feature_selection(random_state=42)\n",
    "    \n",
    "    while iteration < max_iterations and not stop_condition:\n",
    "        print(f\"Iteration {iteration + 1}\")\n",
    "\n",
    "        # 每个分类器分别用已标记的数据进行训练\n",
    "        classifier1.fit(X_train[feature1], y_train)\n",
    "        classifier2.fit(X_train[feature2], y_train)\n",
    "\n",
    "        # 使用两个分类器对未标记的数据进行预测\n",
    "        y_pred1 = classifier1.predict(X_unlabeled)\n",
    "        y_pred2 = classifier2.predict(X_unlabeled)\n",
    "\n",
    "        # 选择每个分类器预测都一致的样本\n",
    "        consistent_indices = (y_pred1 == y_pred2)\n",
    "        consistent_X = X_unlabeled[consistent_indices]\n",
    "        consistent_y = y_pred1[consistent_indices]\n",
    "\n",
    "        # 将一致的样本添加到已标记的数据中\n",
    "        X_train = pd.concat([X_train, consistent_X])\n",
    "        y_train = np.concatenate([y_train, consistent_y])\n",
    "\n",
    "        # 从未标记的数据中移除已经添加到已标记数据的样本\n",
    "        X_unlabeled = X_unlabeled[~consistent_indices]\n",
    "\n",
    "        # 如果未标记数据为空，停止迭代\n",
    "        if len(X_unlabeled) == 0:\n",
    "            stop_condition = True\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    # 使用最终标记的数据重新训练分类器\n",
    "    classifier1.fit(X_train, y_train)\n",
    "    classifier2.fit(X_train, y_train)\n",
    "\n",
    "    # 在测试集上评估性能f\n",
    "    y_pred1 = classifier1.predict(X_test)\n",
    "    y_pred2 = classifier2.predict(X_test)\n",
    "    final_predictions = (y_pred1 + y_pred2) / 2  # 采用平均投票整合两个分类器的预测结果\n",
    "    accuracy, precision, recall, f1, roc_auc, avg_precision = evaluate(y_test, final_predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"ROC AUC Score:\", roc_auc)\n",
    "    print(\"Average Precision Score:\", avg_precision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Label-propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "\n",
    "# 读取数据集\n",
    "data = pd.read_csv(\"9.dataset26criteria.csv\", encoding='gbk')\n",
    "data.dropna(subset=data.columns.difference(['MMSESCORE']), inplace=True)\n",
    "labeled_data = data[data['MMSESCORE'].notnull()]  # 长度为189\n",
    "unlabeled_data = data[data['MMSESCORE'].isnull()]  # 长度为189\n",
    "\n",
    "X_unlabeled = unlabeled_data.drop(columns=['MMSESCORE', 'ID'])  # 长度为21w\n",
    "X_labeled = labeled_data.drop(columns=['MMSESCORE', 'ID'])\n",
    "y_labeled = labeled_data['MMSESCORE']\n",
    "\n",
    "def evaluate(y_true, y_pred, threshold=0.5):\n",
    "    # 将连续目标值转换为二元值\n",
    "    y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "    \n",
    "    # 计算评价指标\n",
    "    accuracy = accuracy_score(y_true, y_pred_binary)\n",
    "    precision = precision_score(y_true, y_pred_binary)\n",
    "    recall = recall_score(y_true, y_pred_binary)\n",
    "    f1 = f1_score(y_true, y_pred_binary)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    avg_precision = average_precision_score(y_true, y_pred)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, roc_auc, avg_precision\n",
    "\n",
    "# 定义随机森林分类器\n",
    "rf_classifier =  classifier_gbc\n",
    "\n",
    "# 定义标签传播算法\n",
    "lp_model = LabelPropagation()\n",
    "\n",
    "# 将标签传播算法与随机森林分类器结合\n",
    "X_combined = pd.concat([X_labeled, X_unlabeled])\n",
    "y_combined = pd.concat([y_labeled, pd.Series([-1] * len(unlabeled_data))])  # 使用-1表示未标记数据\n",
    "\n",
    "# 定义交叉验证\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in kf.split(X_combined):\n",
    "    X_train, X_test = X_combined.iloc[train_index], X_combined.iloc[test_index]\n",
    "    y_train, y_test = y_combined.iloc[train_index], y_combined.iloc[test_index]\n",
    "    \n",
    "    # 使用标签传播算法进行半监督学习，将未标记数据的标签传播给其它数据\n",
    "    lp_model.fit(X_train, y_train)\n",
    "    propagated_labels = lp_model.transduction_\n",
    "\n",
    "    # 使用传播后的标签进行训练\n",
    "    rf_classifier.fit(X_train, propagated_labels[train_index])\n",
    "\n",
    "    # 在测试集上进行预测\n",
    "    y_pred_proba = rf_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # 评估模型性能\n",
    "    accuracy, precision, recall, f1, roc_auc, avg_precision = evaluate(y_test, y_pred_proba)\n",
    "    print(\"Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}, ROC AUC: {:.4f}, Average Precision: {:.4f}\"\n",
    "          .format(accuracy, precision, recall, f1, roc_auc, avg_precision))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Graph semi-supevised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_csv(\"9.dataset26criteria.csv\", encoding='gbk')\n",
    "\n",
    "# Drop rows with missing values except for MMSESCORE column\n",
    "data.dropna(subset=data.columns.difference(['MMSESCORE']), inplace=True)\n",
    "\n",
    "# Separate labeled and unlabeled data\n",
    "labeled_data = data[data['MMSESCORE'].notnull()]  \n",
    "unlabeled_data = data[data['MMSESCORE'].isnull()]  \n",
    "\n",
    "# Extract features and labels\n",
    "X_unlabeled = unlabeled_data.drop(columns=['MMSESCORE', 'ID'])  \n",
    "X_labeled = labeled_data.drop(columns=['MMSESCORE', 'ID'])\n",
    "y_labeled = labeled_data['MMSESCORE']\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate(y_true, y_pred, threshold=0.5):\n",
    "    y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "    accuracy = accuracy_score(y_true, y_pred_binary)\n",
    "    precision = precision_score(y_true, y_pred_binary)\n",
    "    recall = recall_score(y_true, y_pred_binary)\n",
    "    f1 = f1_score(y_true, y_pred_binary)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    avg_precision = average_precision_score(y_true, y_pred)\n",
    "    return accuracy, precision, recall, f1, roc_auc, avg_precision\n",
    "\n",
    "# Define Graph Neural Network model\n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphNet, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Convert data into PyTorch Geometric format\n",
    "X_unlabeled_tensor = torch.tensor(X_unlabeled.values, dtype=torch.float)\n",
    "X_labeled_tensor = torch.tensor(X_labeled.values, dtype=torch.float)\n",
    "y_labeled_tensor = torch.tensor(y_labeled.values, dtype=torch.long)\n",
    "\n",
    "# Create a fully connected graph (you may need to customize this)\n",
    "edge_index = torch.tensor([[i, j] for i in range(len(X_unlabeled)) for j in range(len(X_unlabeled)) if i != j], dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create PyTorch Geometric Data objects\n",
    "unlabeled_data = Data(x=X_unlabeled_tensor, edge_index=edge_index)\n",
    "labeled_data = Data(x=X_labeled_tensor, edge_index=edge_index, y=y_labeled_tensor)\n",
    "\n",
    "# Initialize model parameters\n",
    "input_dim = X_unlabeled.shape[1]\n",
    "hidden_dim = 64\n",
    "output_dim = 2  \n",
    "\n",
    "# Initialize model\n",
    "model = GraphNet(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training\n",
    "def train_model(model, labeled_data, unlabeled_data, optimizer, criterion, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(labeled_data)\n",
    "        loss = criterion(out, labeled_data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "\n",
    "# Train the model\n",
    "train_model(model, labeled_data, unlabeled_data, optimizer, criterion)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
